"""
knowledge_base â†’ context_patterns ë¹ ë¥¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
LLM ì—†ì´ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬
"""

import asyncio
import motor.motor_asyncio
from datetime import datetime
import logging
from typing import List, Dict, Set
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FastContextPatternGenerator:
    """ë¹ ë¥¸ context_patterns ìƒì„±ê¸°"""
    
    def __init__(self, db):
        self.db = db
        self.knowledge_collection = db.knowledge_base
        self.pattern_collection = db.context_patterns
        
        # ë¬¸ë§¥ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (í™•ì¥)
        self.context_keywords = {
            'technical': [
                # í•˜ë“œì›¨ì–´
                'í”„ë¦°í„°', 'ìŠ¤ìºë„ˆ', 'ì¹´ë“œë¦¬ë”ê¸°', 'í‚¤ì˜¤ìŠ¤í¬', 'kiosk', 'ë‹¨ë§ê¸°', 'ì¥ë¹„', 'ê¸°ê¸°',
                # ì†Œí”„íŠ¸ì›¨ì–´
                'í¬ìŠ¤', 'pos', 'í”„ë¡œê·¸ë¨', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ë“œë¼ì´ë²„', 'ì„¤ì¹˜', 'ì¬ì„¤ì¹˜',
                # ì‹œìŠ¤í…œ
                'ì‹œìŠ¤í…œ', 'ë„¤íŠ¸ì›Œí¬', 'ì—°ê²°', 'ì¸í„°ë„·', 'ì„¤ì •', 'ì—…ë°ì´íŠ¸',
                # ë¬¸ì œ í•´ê²°
                'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë¬¸ì œ', 'í•´ê²°', 'ìˆ˜ì •', 'ê³ ì¥', 'ì•ˆë¨', 'ì•ˆë˜',
                # ë°ì´í„°
                'ë°ì´í„°', 'ë°±ì—…', 'ë³µêµ¬', 'ì €ì¥', 'ì‚­ì œ', 'ì´ë™',
                # ê²°ì œ
                'ê²°ì œ', 'ì¹´ë“œ', 'ì˜ìˆ˜ì¦', 'ë°”ì½”ë“œ', 'qrì½”ë“œ', 'qr', 'ì§ì¸', 'ë„ì¥',
                # ê¸°íƒ€ ê¸°ìˆ 
                'ì›ê²©', 'ì ‘ì†', 'ë¡œê·¸ì¸', 'ë¹„ë°€ë²ˆí˜¸', 'ê³„ì •', 'ê¶Œí•œ', 'ë³´ì•ˆ'
            ],
            'casual': [
                # ì¸ì‚¬ë§
                'ì•ˆë…•', 'ë°˜ê°‘', 'í•˜ì´', 'hello', 'hi', 'ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°‘ìŠµë‹ˆë‹¤',
                # ì¼ìƒ
                'ë°”ì˜', 'ì‹ì‚¬', 'ì ì‹¬', 'ì €ë…', 'ì•„ì¹¨', 'ì»¤í”¼', 'ì°¨', 'ë‚ ì”¨',
                # ê°ì •/ìƒíƒœ
                'ê¸°ë¶„', 'í”¼ê³¤', 'í˜ë“œ', 'ì–´ë–»ê²Œ ì§€ë‚´', 'ì˜ ì§€ë‚´', 'ê´œì°®',
                # AI ê´€ë ¨
                'ë„ˆëŠ”', 'ë‹¹ì‹ ì€', 'ai', 'ì¸ê³µì§€ëŠ¥', 'ë¡œë´‡', 'ë´‡', 'ì±—ë´‡'
            ],
            'non_counseling': [
                # êµ­ê°€/ì§€ì—­
                'í•œêµ­', 'ëŒ€í•œë¯¼êµ­', 'ì¼ë³¸', 'ì¤‘êµ­', 'ë¯¸êµ­', 'ì˜êµ­', 'í”„ë‘ìŠ¤',
                # ì—­ì‚¬/ì§€ë¦¬
                'ì—­ì‚¬', 'ì§€ë¦¬', 'ìˆ˜ë„', 'ì¸êµ¬', 'ë©´ì ', 'ì–¸ì–´', 'ë¬¸í™”',
                # ì •ì¹˜/ê²½ì œ
                'ì •ì¹˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'ì •ë¶€', 'ëŒ€í†µë ¹', 'êµ­íšŒ',
                # ê³¼í•™/í•™ë¬¸
                'ê³¼í•™', 'ìˆ˜í•™', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒë¬¼', 'ì²œë¬¸', 'ì§€êµ¬',
                # ì¼ë°˜ ì§€ì‹
                'ì„¸ê³„', 'ìš°ì£¼', 'ìì—°', 'ë™ë¬¼', 'ì‹ë¬¼', 'ìŒì‹', 'ìŠ¤í¬ì¸ '
            ],
            'profanity': [
                # ìš•ì„¤/ë¹„ì†ì–´
                'ë°”ë³´', 'ë©ì²­', 'ë˜¥', 'ê°œ', 'ìƒˆë¼', 'ì”¨ë°œ', 'ë³‘ì‹ ', 'ë¯¸ì¹œ', 'ë¯¸ì³¤',
                'ëŒì•˜', 'ì •ì‹ ', 'ë¹¡', 'ë¹¡ì¹˜', 'ê°œìƒˆë¼', 'ë³‘ì‹ ', 'ë¯¸ì³¤ë‹¤'
            ]
        }
    
    def _classify_by_keywords(self, question: str) -> str:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ë§¥ ë¶„ë¥˜"""
        question_lower = question.lower()
        
        # ê° ë¬¸ë§¥ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scores = {}
        for context, keywords in self.context_keywords.items():
            score = sum(1 for keyword in keywords if keyword in question_lower)
            scores[context] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë¬¸ë§¥ ë°˜í™˜
        if scores:
            max_score = max(scores.values())
            if max_score > 0:
                return max(scores, key=scores.get)
        
        return 'technical'  # ê¸°ë³¸ê°’ (ìƒë‹´ ë°ì´í„°ì´ë¯€ë¡œ)
    
    def _generate_variations(self, question: str, context: str) -> List[str]:
        """ì§ˆë¬¸ì˜ ë‹¤ì–‘í•œ ë³€í˜• ìƒì„±"""
        variations = [question]  # ì›ë³¸ í¬í•¨
        
        # ê¸°ë³¸ ë³€í˜• íŒ¨í„´
        basic_patterns = [
            # ì§ˆë¬¸ í˜•íƒœ ë³€í˜•
            lambda q: q.replace('?', '').strip(),
            lambda q: q.replace('?', 'ìš”').strip(),
            lambda q: q.replace('?', 'ì¸ê°€ìš”').strip(),
            lambda q: q.replace('?', 'í• ê¹Œìš”').strip(),
            lambda q: q.replace('?', 'í•˜ë‚˜ìš”').strip(),
            
            # ì¡´ëŒ“ë§ ë³€í˜•
            lambda q: q.replace('ìš”', '').strip(),
            lambda q: q.replace('ìš”', 'ë‹¤').strip(),
            lambda q: q.replace('ë‹ˆë‹¤', '').strip(),
            lambda q: q.replace('ë‹ˆë‹¤', 'ë‹¤').strip(),
            
            # ì¡°ì‚¬ ë³€í˜•
            lambda q: q.replace('ê°€', 'ì´').strip(),
            lambda q: q.replace('ì´', 'ê°€').strip(),
            lambda q: q.replace('ë¥¼', 'ì„').strip(),
            lambda q: q.replace('ì„', 'ë¥¼').strip(),
            lambda q: q.replace('ì—', 'ì—ì„œ').strip(),
            lambda q: q.replace('ì—ì„œ', 'ì—').strip(),
            
            # ë¶€ì •ì–´ ë³€í˜•
            lambda q: q.replace('ì•ˆ', 'ì•ˆ').strip(),
            lambda q: q.replace('ì•ˆ', 'ëª»').strip(),
            lambda q: q.replace('ëª»', 'ì•ˆ').strip(),
        ]
        
        # ê¸°ë³¸ ë³€í˜• ì ìš©
        for pattern in basic_patterns:
            try:
                variation = pattern(question)
                if variation != question and len(variation) > 5:
                    variations.append(variation)
            except:
                continue
        
        # ë¬¸ë§¥ë³„ íŠ¹í™” ë³€í˜•
        if context == 'technical':
            tech_variations = [
                lambda q: f"{q} ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
                lambda q: f"{q} ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
                lambda q: f"{q} ì„¤ì • ë°©ë²•",
                lambda q: f"{q} ë¬¸ì œ í•´ê²°",
                lambda q: f"{q} ì˜¤ë¥˜ ìˆ˜ì •",
                lambda q: f"{q} ê³ ì¹˜ëŠ” ë°©ë²•",
                lambda q: f"{q} í•´ê²°ì±…",
                lambda q: f"{q} ëŒ€ì²˜ë²•",
            ]
            
            for pattern in tech_variations:
                try:
                    variation = pattern(question)
                    if len(variation) < 100:  # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
                        variations.append(variation)
                except:
                    continue
        
        elif context == 'casual':
            casual_variations = [
                lambda q: f"{q} ì–´ë–»ê²Œ ìƒê°í•´?",
                lambda q: f"{q} ê´œì°®ì„ê¹Œ?",
                lambda q: f"{q} ì–´ë– ì„¸ìš”?",
                lambda q: f"{q} ì–´ë– ì‹ ê°€ìš”?",
            ]
            
            for pattern in casual_variations:
                try:
                    variation = pattern(question)
                    if len(variation) < 80:
                        variations.append(variation)
                except:
                    continue
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
        unique_variations = []
        seen = set()
        for variation in variations:
            if variation not in seen and 5 <= len(variation) <= 100:
                unique_variations.append(variation)
                seen.add(variation)
        
        return unique_variations[:8]  # ìµœëŒ€ 8ê°œ ë³€í˜• (ë¹ ë¥¸ ì²˜ë¦¬)
    
    async def generate_patterns_fast(self) -> Dict:
        """ë¹ ë¥¸ íŒ¨í„´ ìƒì„±"""
        logger.info("ë¹ ë¥¸ context_patterns ìƒì„± ì‹œì‘...")
        
        # ê¸°ì¡´ íŒ¨í„´ ìˆ˜ í™•ì¸
        existing_count = await self.pattern_collection.count_documents({})
        logger.info(f"ê¸°ì¡´ context_patterns ìˆ˜: {existing_count}")
        
        # knowledge_baseì—ì„œ ëª¨ë“  ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
        questions = []
        async for doc in self.knowledge_collection.find({}):
            question = doc.get("question", "").strip()
            if question and len(question) > 5:
                questions.append({
                    "question": question,
                    "answer": doc.get("answer", ""),
                    "category": doc.get("category", "technical"),
                    "keywords": doc.get("keywords", [])
                })
        
        logger.info(f"ì²˜ë¦¬í•  ì§ˆë¬¸ ìˆ˜: {len(questions)}")
        
        # ë¬¸ë§¥ë³„ í†µê³„
        context_stats = {'technical': 0, 'casual': 0, 'non_counseling': 0, 'profanity': 0}
        total_patterns = 0
        
        # ê° ì§ˆë¬¸ì— ëŒ€í•´ íŒ¨í„´ ìƒì„±
        for i, q_data in enumerate(questions, 1):
            question = q_data["question"]
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ë¬¸ë§¥ ë¶„ë¥˜ (ë¹ ë¦„)
            context = self._classify_by_keywords(question)
            context_stats[context] += 1
            
            # ë³€í˜• íŒ¨í„´ ìƒì„±
            variations = self._generate_variations(question, context)
            
            # íŒ¨í„´ ì €ì¥
            for variation in variations:
                pattern_doc = {
                    "pattern": variation,
                    "context": context,
                    "original_question": question,
                    "is_active": True,
                    "accuracy": 0.85,  # í‚¤ì›Œë“œ ê¸°ë°˜ì´ë¯€ë¡œ ì•½ê°„ ë‚®ìŒ
                    "usage_count": 0,
                    "created_at": datetime.now(),
                    "updated_at": datetime.now(),
                    "source": "knowledge_base_fast_generated"
                }
                
                # ì¤‘ë³µ ì²´í¬ í›„ ì €ì¥
                existing = await self.pattern_collection.find_one({"pattern": variation})
                if not existing:
                    await self.pattern_collection.insert_one(pattern_doc)
                    total_patterns += 1
            
            # ì§„í–‰ë¥  ì¶œë ¥ (ë” ìì£¼)
            if i % 20 == 0:
                logger.info(f"ì§„í–‰ë¥ : {i}/{len(questions)} ({i/len(questions)*100:.1f}%) - ìƒì„±ëœ íŒ¨í„´: {total_patterns}ê°œ")
        
        # ìµœì¢… í†µê³„
        final_count = await self.pattern_collection.count_documents({})
        
        result = {
            "original_patterns": existing_count,
            "new_patterns_generated": total_patterns,
            "total_patterns": final_count,
            "context_distribution": context_stats,
            "questions_processed": len(questions)
        }
        
        logger.info("=== ë¹ ë¥¸ ë³€í™˜ ì™„ë£Œ ===")
        logger.info(f"ê¸°ì¡´ íŒ¨í„´: {existing_count}ê°œ")
        logger.info(f"ìƒˆë¡œ ìƒì„±: {total_patterns}ê°œ")
        logger.info(f"ì´ íŒ¨í„´: {final_count}ê°œ")
        logger.info("ë¬¸ë§¥ë³„ ë¶„í¬:")
        for context, count in context_stats.items():
            logger.info(f"  - {context}: {count}ê°œ")
        
        return result
    
    async def cleanup_duplicate_patterns(self) -> Dict:
        """ì¤‘ë³µ íŒ¨í„´ ì •ë¦¬"""
        logger.info("ì¤‘ë³µ íŒ¨í„´ ì •ë¦¬ ì‹œì‘...")
        
        # ëª¨ë“  íŒ¨í„´ ê°€ì ¸ì˜¤ê¸°
        patterns = []
        async for doc in self.pattern_collection.find({}):
            patterns.append(doc)
        
        # ì¤‘ë³µ íŒ¨í„´ ì°¾ê¸°
        seen_patterns = set()
        duplicates = []
        
        for pattern_doc in patterns:
            pattern = pattern_doc["pattern"].strip().lower()
            if pattern in seen_patterns:
                duplicates.append(pattern_doc["_id"])
            else:
                seen_patterns.add(pattern)
        
        # ì¤‘ë³µ íŒ¨í„´ ì‚­ì œ
        if duplicates:
            result = await self.pattern_collection.delete_many({"_id": {"$in": duplicates}})
            deleted_count = result.deleted_count
        else:
            deleted_count = 0
        
        final_count = await self.pattern_collection.count_documents({})
        
        logger.info(f"ì¤‘ë³µ íŒ¨í„´ ì‚­ì œ: {deleted_count}ê°œ")
        logger.info(f"ìµœì¢… íŒ¨í„´ ìˆ˜: {final_count}ê°œ")
        
        return {
            "duplicates_removed": deleted_count,
            "final_patterns": final_count
        }

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # MongoDB ì—°ê²°
    client = motor.motor_asyncio.AsyncIOMotorClient("mongodb://localhost:27017")
    db = client.aicounsel
    
    try:
        generator = FastContextPatternGenerator(db)
        
        print("ğŸš€ ë¹ ë¥¸ context_patterns ìƒì„± ì‹œì‘!")
        print("   - LLM ì—†ì´ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬")
        print("   - ì˜ˆìƒ ì‹œê°„: 1-2ë¶„")
        
        # 1. íŒ¨í„´ ìƒì„±
        result = await generator.generate_patterns_fast()
        
        # 2. ì¤‘ë³µ ì •ë¦¬
        cleanup_result = await generator.cleanup_duplicate_patterns()
        
        # 3. ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ‰ ë¹ ë¥¸ context_patterns ìƒì„± ì™„ë£Œ!")
        print(f"   - ê¸°ì¡´: {result['original_patterns']}ê°œ")
        print(f"   - ìƒˆë¡œ ìƒì„±: {result['new_patterns_generated']}ê°œ")
        print(f"   - ì¤‘ë³µ ì œê±°: {cleanup_result['duplicates_removed']}ê°œ")
        print(f"   - ìµœì¢…: {cleanup_result['final_patterns']}ê°œ")
        print(f"   - ì²˜ë¦¬ëœ ì§ˆë¬¸: {result['questions_processed']}ê°œ")
        
        print(f"\nğŸ“Š ë¬¸ë§¥ë³„ ë¶„í¬:")
        for context, count in result['context_distribution'].items():
            print(f"   - {context}: {count}ê°œ")
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    finally:
        client.close()

if __name__ == "__main__":
    asyncio.run(main()) 