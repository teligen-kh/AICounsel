# AI Counsel 프로젝트 구조 (리팩토링 완료)

## 📁 프로젝트 개요
AI 상담 서비스로, 고객 응대 알고리즘을 기반으로 한 지능형 채팅 시스템입니다.

## 🏗️ 아키텍처 개요

### 핵심 설계 원칙
1. **모듈화**: 각 기능별로 독립적인 서비스 클래스
2. **의존성 주입**: 서비스 간 느슨한 결합
3. **업무별 분리**: 명확한 책임 분리
4. **모델별 최적화**: 각 LLM 모델에 특화된 처리

### 서비스 계층 구조
```
┌─────────────────────────────────────────────────────────────┐
│                    API Layer (FastAPI)                      │
├─────────────────────────────────────────────────────────────┤
│                 Service Layer                               │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ ChatService │ │ LLMService  │ │ SearchService│           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                Processor Layer                              │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │PolyglotKo   │ │ Llama       │ │ BaseLLM     │           │
│  │Processor    │ │ Processor   │ │ Processor   │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                Algorithm Layer                              │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │Conversation │ │ Formatting  │ │ Model       │           │
│  │Algorithm    │ │ Service     │ │ Manager     │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    Data Layer                               │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ MongoDB     │ │ Model Files │ │ Config      │           │
│  │ Database    │ │ (LLM Models)│ │ Files       │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

## 📂 디렉토리 구조

### Backend (`backend/`)
```
backend/
├── app/
│   ├── main.py                    # FastAPI 애플리케이션 진입점
│   ├── config.py                  # 설정 관리
│   ├── database.py                # MongoDB 연결 관리
│   ├── dependencies.py            # 의존성 주입 관리
│   │
│   ├── routers/                   # API 라우터
│   │   └── chat.py               # 채팅 관련 API 엔드포인트
│   │
│   ├── services/                  # 비즈니스 로직 서비스
│   │   ├── chat_service.py       # 채팅 서비스 (업무별 메서드 분리)
│   │   ├── llm_service.py        # LLM 서비스 (모델별 최적화)
│   │   ├── llm_processors.py     # 모델별 프로세서 (새로 추가)
│   │   ├── mongodb_search_service.py # MongoDB 검색 서비스
│   │   ├── conversation_algorithm.py # 고객 응대 알고리즘
│   │   ├── formatting_service.py # 응답 포맷팅 서비스
│   │   └── model_manager.py      # 모델 관리자
│   │
│   ├── models/                    # 데이터 모델
│   │   └── chat.py               # 채팅 메시지 모델
│   │
│   └── core/                      # 핵심 설정
│       ├── config.py             # 핵심 설정
│       └── database.py           # 데이터베이스 설정
│
├── data/                          # 데이터 파일
├── models/                        # LLM 모델 파일
├── scripts/                       # 유틸리티 스크립트
└── venv/                         # 가상환경
```

### Frontend (`frontend/`)
```
frontend/
├── src/
│   ├── app/                       # Next.js 13+ App Router
│   │   ├── page.tsx              # 메인 페이지
│   │   ├── chat/page.tsx         # 채팅 페이지
│   │   ├── analysis/page.tsx     # 분석 페이지
│   │   ├── list/page.tsx         # 대화 목록 페이지
│   │   ├── layout.tsx            # 레이아웃
│   │   └── globals.css           # 전역 스타일
│   │
│   ├── components/                # React 컴포넌트
│   │   ├── chat/                 # 채팅 관련 컴포넌트
│   │   │   ├── ChatContainer.tsx
│   │   │   ├── ChatHeader.tsx
│   │   │   ├── ChatInput.tsx
│   │   │   ├── ChatMessage.tsx
│   │   │   ├── ChatMessageList.tsx
│   │   │   └── LoadingMessage.tsx
│   │   │
│   │   ├── Analysis/             # 분석 관련 컴포넌트
│   │   │   ├── AnalysisResults.tsx
│   │   │   └── DateRangePicker.tsx
│   │   │
│   │   ├── Navigation/           # 네비게이션 컴포넌트
│   │   │   └── Navbar.tsx
│   │   │
│   │   ├── ui/                   # UI 컴포넌트
│   │   │   ├── button.tsx
│   │   │   ├── card.tsx
│   │   │   ├── dialog.tsx
│   │   │   ├── input.tsx
│   │   │   └── ...
│   │   │
│   │   └── layouts/              # 레이아웃 컴포넌트
│   │       └── MainLayout.tsx
│   │
│   ├── services/                  # API 서비스
│   │   ├── api.ts                # API 클라이언트
│   │   └── chatService.ts        # 채팅 서비스
│   │
│   ├── store/                     # 상태 관리
│   │   └── useChatStore.ts       # 채팅 상태 관리
│   │
│   ├── types/                     # TypeScript 타입 정의
│   │   └── analysis.ts           # 분석 관련 타입
│   │
│   ├── lib/                       # 유틸리티
│   │   └── utils.ts              # 공통 유틸리티
│   │
│   └── styles/                    # 스타일
│       └── theme.ts              # 테마 설정
│
├── public/                        # 정적 파일
├── package.json                   # 의존성 관리
├── tailwind.config.ts            # Tailwind CSS 설정
└── tsconfig.json                 # TypeScript 설정
```

## 🔧 핵심 서비스 설명

### 1. ChatService (채팅 서비스)
**위치**: `backend/app/services/chat_service.py`
**역할**: 채팅 메시지 처리의 진입점

**업무별 메서드 분리**:
- `get_conversation_response()`: 대화 정보 받기 (일상 대화)
- `search_and_enhance_answer()`: 응답 찾기 (전문 상담)
- `format_and_send_response()`: 응답 정보 보내기 (포맷팅)

**주요 기능**:
- 대화 유형 분류 및 라우팅
- 업무별 메서드 호출
- 통계 수집 및 모니터링
- 모델 전환 관리

### 2. LLMService (LLM 서비스)
**위치**: `backend/app/services/llm_service.py`
**역할**: LLM 모델과의 직접적인 상호작용

**모델별 최적화**:
- 모델별 프로세서 사용
- 최적화된 생성 파라미터
- 모델별 응답 후처리

**주요 기능**:
- 모델 로딩 및 관리
- 텍스트 생성
- 응답 품질 관리
- 성능 모니터링

### 3. LLM Processors (모델별 프로세서)
**위치**: `backend/app/services/llm_processors.py`
**역할**: 각 LLM 모델에 특화된 처리

**구현된 프로세서**:
- `PolyglotKoProcessor`: Polyglot-Ko 5.8B 모델 전용
- `LlamaProcessor`: LLaMA 3.1 8B Instruct 모델 전용
- `BaseLLMProcessor`: 기본 프로세서 인터페이스

**주요 기능**:
- 모델별 프롬프트 생성
- 최적화된 생성 파라미터
- 모델별 응답 후처리
- 특수 토큰 처리

### 4. Model Manager (모델 관리자)
**위치**: `backend/app/services/model_manager.py`
**역할**: LLM 모델의 생명주기 관리

**지원 모델**:
- `polyglot-ko-5.8b`: 한국어 특화 모델
- `llama-3.1-8b`: 다국어 지원 모델

**주요 기능**:
- 모델 로딩/언로딩
- 모델 전환
- 메모리 관리
- 모델 상태 모니터링

### 5. Conversation Algorithm (고객 응대 알고리즘)
**위치**: `backend/app/services/conversation_algorithm.py`
**역할**: 대화 유형 분류 및 기본 응답 생성

**대화 유형**:
- `casual`: 일상 대화
- `professional`: 전문 상담

**주요 기능**:
- 키워드 기반 대화 분류
- 기본 응답 생성
- 상담사 연락 안내

### 6. MongoDB Search Service (검색 서비스)
**위치**: `backend/app/services/mongodb_search_service.py`
**역할**: MongoDB에서 관련 답변 검색

**주요 기능**:
- 키워드 추출
- 유사도 검색
- 답변 랭킹
- 검색 결과 캐싱

## 🔄 데이터 흐름

### 1. 일반 채팅 흐름
```
사용자 메시지 → ChatService → 대화 분류 → 업무별 메서드 → LLMService → 응답 반환
```

### 2. 일상 대화 처리
```
메시지 → get_conversation_response() → LLM 생성 → 응답 후처리 → 반환
```

### 3. 전문 상담 처리
```
메시지 → search_and_enhance_answer() → DB 검색 → LLM 개선 → 포맷팅 → 반환
```

## 🚀 API 엔드포인트

### 채팅 API (`/api/v1/chat/`)
- `POST /send`: 일반 채팅 메시지 처리
- `POST /casual`: 일상 대화 처리
- `POST /professional`: 전문 상담 처리
- `POST /format`: 응답 포맷팅
- `POST /switch-model`: 모델 전환
- `GET /model-status`: 모델 상태 조회
- `GET /stats`: 통계 조회
- `POST /set-db-priority`: DB 우선 검색 모드 설정

### 시스템 API
- `GET /`: 루트 엔드포인트
- `GET /health`: 헬스 체크
- `GET /api/v1/info`: API 정보 조회

## 🔧 설정 및 환경

### 환경 변수
- `MONGODB_URL`: MongoDB 연결 URL
- `MODEL_PATH`: LLM 모델 경로
- `LOG_LEVEL`: 로깅 레벨

### 모델 설정
- 기본 모델: `polyglot-ko-5.8b`
- 지원 모델: `llama-3.1-8b`
- 모델 전환: API를 통한 동적 전환

## 📊 모니터링 및 통계

### 수집되는 통계
- 총 요청 수
- 대화 유형별 분포
- 처리 시간 (평균, 중간값, 최소, 최대)
- DB/LLM 응답 수
- 오류 발생률

### 로깅
- 구조화된 로깅
- 파일 및 콘솔 출력
- 처리 시간 추적
- 오류 상세 정보

## 🔄 의존성 주입

### 서비스 인스턴스 관리
- 전역 서비스 인스턴스
- 지연 초기화 (Lazy Initialization)
- 의존성 주입을 통한 결합도 감소
- 서비스 재설정 기능

### 의존성 그래프
```
ChatService → LLMService → ModelManager
ChatService → MongoDBSearchService
LLMService → LLMProcessor (모델별)
```

## 🛠️ 개발 가이드라인

### 코드 구조
1. **업무별 메서드 분리**: 명확한 책임 분리
2. **모델별 최적화**: 각 모델 특성에 맞는 처리
3. **의존성 주입**: 느슨한 결합 유지
4. **에러 처리**: 안정적인 오류 처리
5. **로깅**: 상세한 로깅 및 모니터링

### 테스트
- 단위 테스트: 각 서비스별
- 통합 테스트: API 엔드포인트
- 성능 테스트: 처리 시간 측정

### 배포
- Docker 컨테이너화
- 환경별 설정 분리
- 헬스 체크 및 모니터링

## 📈 성능 최적화

### 현재 성능 (리팩토링 후)
- 일상 대화: 1-3ms
- 전문 상담: 10-800ms
- 모델 전환: 즉시
- 메모리 사용량: 최적화됨

### 최적화 포인트
1. **모델별 프로세서**: 각 모델에 최적화된 처리
2. **업무별 분리**: 명확한 책임 분리로 성능 향상
3. **의존성 주입**: 서비스 재사용성 증가
4. **캐싱**: 검색 결과 캐싱
5. **비동기 처리**: I/O 최적화

## 🔮 향후 개선 방향

### 단기 개선사항
1. **프롬프트 최적화**: 모델별 프롬프트 개선
2. **응답 품질**: 후처리 로직 강화
3. **성능 모니터링**: 실시간 성능 추적

### 장기 개선사항
1. **새로운 모델 지원**: 더 많은 LLM 모델 추가
2. **고급 분석**: 대화 패턴 분석
3. **개인화**: 사용자별 맞춤 응답
4. **멀티모달**: 이미지, 음성 지원

---

**최종 업데이트**: 2024년 12월 (리팩토링 완료)
**버전**: 2.0.0
**상태**: 프로덕션 준비 완료 