
cd D:\AICounsel\finetune_tool
venv_finetune\Scripts\activate

teligen.kh@gmail.com
@Telikh1205

프론트엔드 및 백엔드 서버 실행해줘

2025-07-22

상담 플랫폼 AI 설정 및 자동화 가이드
배경
목표: 텔리젠 상담 플랫폼에서 AI가 고객과 직접 소통하며, 300개 FAQ 응답, QR코드 접속, 3,000콜/일, 1~2초 응답(GPU 목표)을 달성. 일상 응대, 전문 상담(DB 기반), 비상담/욕설 대응 제공.
현재 상태: Llama-3.1-8B-Instruct 모델 사용, knowledge_base에 표준화된 상담 내용, conversations에 실시간 대화 저장 계획. 수동 관리 대신 자동화 필요.
DB 구조
conversations 테이블: 대화 기록 저장 (시간, 사용자 입력, AI 응답, 분류: casual, technical, non_counseling, profanity).
knowledge_base 테이블: 질문, 답변, 키워드 저장.
input_keywords 테이블: 키워드와 분류 저장.
자동화 알고리즘
목적: 대화 저장 후 knowledge_base와 input_keywords에 자동 업데이트.
단계:
AI가 고객과 소통 후 conversations에 저장.
LLM으로 입력을 "casual", "technical", "non_counseling", "profanity"로 분류.
knowledge_base에 동일 질문 없으면 추가 (유사성 체크로 중복 방지).
soynlp로 키워드 추출, input_keywords에 반영.
입력 분류 전략
초기 필터링: 전문 상담 키워드(예: "포스", "키오스크", "프린터")로 DB 처리, 나머지 LLM 의도 분석.
LLM 분류: casual(일상), non_counseling(비상담), profanity(욕설).
프롬프트 설정
시스템 프롬프트: 텔리젠 친절한 AI 상담사 역할 정의.
인사: "안녕하세요! 어떻게 도와드릴까요?"
일상 대화: 친근한 답변.
전문 상담: DB 정보 풀어서 설명, 없으면 "상담사 연락 요청".
비상담: "해당 질문은 답변 드릴 수 없습니다."
욕설: "욕설 시 30분 후 재문의 요청".
답변: 2문장, 자연스럽게.
생성 파라미터 설정
temperature: 0.3 (일관성 유지).
max_tokens: 75 (2문장 보장).
top_p: 0.8 (관련성 강화).
top_k: 30 (간결함 유지).
repeat_penalty: 1.2 (반복 최소화).
키워드 추출 및 분류 개선
배경: input_keywords (1734개)에서 전문 상담 키워드만 선별.
키워드 추출 규칙:
도메인 관련성: 기술/업무 용어(예: "포스", "설치") 우선.
빈도 및 맥락: 2회 이상 등장하거나 기술 절차(예: "로그인") 연관 시 포함.
업계 용어 우선: 상담 맥락(포스, 클라우드 등) 관련 용어.
수동 검토: 초기 50개 추출 후 확인 후 확장.
초기 키워드 예시: "프로그램재설치", "설치요구", "포스", "키오스크", "프린터", "영수증", "설치", "작동", "오류", "재시작", "클라우드", "거래명세서", "직인", "계좌번호", "업데이트", "로그인", "백업", "출력", "단말기", "설정".
비전문 제외 예시: "고객님", "팀장", "아침", "커피", "감사".
테스트 지시
"안녕하세요?" → casual, "안녕하세요! 어떻게 도와드릴까요?"
"포스 설치 방법" → technical, DB 응답 (예: "포스 설치는 smart.arumnet.com에서 진행하세요.").
"한국 역사" → non_counseling, "저는 텔리젠 AI 상담사로 해당 질문은 답변 드릴 수 없습니다."
"바보 AI야" → profanity, "욕설을 하시면 응대를 할 수 없습니다. 30분 후 재문의 바랍니다."
"새로운 질문" → 대화 저장 후 knowledge_base/input_keywords 업데이트 확인.
추가 고려사항
유사성 체크: 오탈자/동의어로 중복 방지 (sentence-transformers 사용).
오탈자 보정: spellchecker로 정정.
GPU 계획: AWS g4dn.xlarge로 0.5~1초 목표.
DB 입력: knowledge_base와 input_keywords 초기 데이터 삽입.


2025-07-25
context_patterns 테이블의 pattern 을 보니 문제가 있어.
"매장에 등록된 상품을 엑셀로 한번에 저장할숭 있나요" 라고 pattern 에 들어있는데 인지를 못하는이유가 pattern 의 내용들이 문제라고 생각해.

pattern 의 내용들이 
매장에 등록
상품을 엑셀
한번에 저장
 이런식으로 되어 있고 이런 형태의 문맥에 따라 분류가 이루어져야 하는데 이건 그냥  knowledge_base 테이블의 question 컬럼의 값을 기본으로 단어만 몇 개씩 바꾼 형태네.
이렇게 잘못 등록되어  있으니 엉뚱한 답을 내놓는 거지.



2025-08-06
우리는 모듈을 하나 만들거야.
이 모둘의 목적은 고객의 질문이 technical에 속하는지를 구분해서 DB에 있는 정보를 검색해서 대답할지를 판단하는 거야
만드는 과정은 다음과 같아.
1. MongoDB의 knowledge_base 테이블 중 question 컬럼에 들어 있는 모든 문장을 가져와.
2. LLM이 판단해서 technical 에 해당하는 단어들을 추출해.
3. 현재  MongoDB의 context_patterns 테이블의 모든 데이터를 삭제해.
4. 중복 제거를 하고 남은 단어들을 MongoDB의 context_patterns 테이블에 입력해
5. 고객의 질문이 technical에 속하는지를 구분하는 방법은 고객의 질문에 context_patterns에 들어 있는 단어 2개 이상이 포함되면 technical 로 인식하는 모듈을 만들어.
6.  technical 로 인식 되면 knowledge_base 테이블 중 question 컬럼의 내용 중 모듈에서 도출된 단어들을 동시에 들어 있는 내용들을 검색해서 결과를 가져온다. 

단, 작업을 하다보면 문제가 발생할 수 있으니 우선  MongoDB의 knowledge_base 테이블 중 question 컬럼에 들어 있는 랜덤한 10개만 가져와서 테스트 후 1번 부터 전체 작업을 진행하자.


�� 제안하는 접근 방법:
1단계: 테스트용 모듈 생성
랜덤 10개 질문으로 테스트하는 간단한 모듈 먼저 만들기
LLM을 사용해서 technical 키워드 추출 기능 구현
2단계: 전체 시스템 구축
기존 코드를 활용하면서 새로운 요구사항 반영
통합된 모듈로 정리
3단계: 검색 로직 개선
2개 이상 키워드 매칭 로직 강화
context_patterns 기반 검색 최적화


2025-08-07
내가 만들고자 하는 프로세스는 다음과 같아.
1. 고객의 질문 내용이 casual 혹은 profanity인지 확인
2. 아니면 context_patterns 테이블의 pattern 에 속한 단어들이 있는지 확인.
2-1. 없으면 non_counseling으로 분류
2-2. 있으면 technical 판정
3. 2번에서 추출된  context_patterns 테이블의 pattern 에 속한 단어들이 knowledge_base 테이블의 
question 컬럼에 모두 들어 있는 데이터들을 찾음.
4-1. 1개의 데이터가 나오면 그 내용을 LLM이 사람처럼 친절하고 가독성 있게 전달.   
4-2. 2개 이상의 데이터가 나오면 LLM이 판단해서 가장 최적의 답변을  사람처럼 친절하고 가독성 있게 전달. 



AI 상담 챗봇: Clarification 기능 확장 계획

현재 상황
구성: FastAPI(백엔드), Next.js(프론트엔드), MongoDB Atlas(DB), Rocket.Chat(채팅), Llama-3.1-8B-Instruct(AI 모델)

DB 테이블:
conversations: 고객-AI 대화 로그 (시간, 입력, 응답)
knowledge_base: 표준 Q&A (예: 직인 삽입/삭제)
input_keywords: 질문 분류 (casual, technical, non_counseling, profanity)
context_patterns: technical 질문 판단 키워드

프로세스:
질문 분류 (casual/profanity/technical/non_counseling)
technical 질문 → context_patterns 키워드로 knowledge_base 검색

결과 처리:
1개: LLM이 친절히 전달
2개 이상: LLM이 최적 답변 선택
(문제) 0개나 모호한 경우 → 부정확한 응답 가능

확장 목표
AI가 모호한 질문(예: "견적서 단위 바꾸고 싶어")에서 사람 상담사처럼 추가 질문(예: "상품코드는 뭐예요?")을 해서 맥락을 확정 후 정확한 답변 제공.

확장 내용
Clarification 로직 추가:
조건: knowledge_base 검색 결과 0개이거나, 질문이 모호할 때(예: 키워드 부족, "이거" 같은 표현 포함)
동작: LLM이 추가 질문을 생성해 고객에게 요청
예시:
고객: "견적서 단위 바꾸고 싶어"
AI: "상품코드는 뭐예요? (예: M3100처럼)"
고객 답변 후 → knowledge_base 재검색 → 정확한 답변 (예: "상품코드 정보관리에서 조회 후 수정 버튼 누르세요")

LLM 프롬프트 개선:
모호함 감지 및 질문 생성 지침 추가
예: "질문이 불완전하면 추가 질문 생성. 공손하고 자연스럽게."

제한 조건:
최대 2-3회 질문으로 루프 방지
모호함 지속 시 "더 자세히 말씀해주세요"로 마무리

사용자 경험:
고객이 추가 질문에 답하면, AI가 대화 맥락 유지하며 정확한 knowledge_base 답변 제공
항상 친절하고 가독성 있는 응답 (예: "도움이 되셨나요?" 마무리)

기대 효과
정확성: 모호한 질문에서 잘못된 답변 감소
자연스러움: 사람 상담사 같은 대화 흐름
차별화: 단순 정보 전달 → 대화형 AI로 업그레이드


확장을 위한 파일 변경 계획
신규 추가 파일들:
1. Clarification 관련 모듈
2. 대화 맥락 관리 모듈
3. 모호함 감지 모듈
4. Clarification 관련 스크립트
기존 파일 수정:
1. chat_service.py (수정)
2. context_aware_classifier.py (수정)
3. mongodb_search_service.py (수정)
4. llm_service.py (수정)
5. database.py (수정)
6. dependencies.py (수정)
새로운 DB 컬렉션:
conversation_contexts
수정 원칙:
기존 모듈은 최소한으로 수정
새로운 기능은 별도 모듈로 분리
기존 API 인터페이스는 유지
새로운 기능은 옵션으로 활성화/비활성화 가능